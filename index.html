<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Deep Learning</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>




<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis"></script>
  <script src="data.js" type="module"></script>

          <script src="https://cdn.jsdelivr.net/npm/chart.js"></script> 
  <script src="script.js" type="module"></script>

<link rel="stylesheet" href="./mnist.css">
<style>
        .container {
            display: flex;
            align-items: center; /* Aligns items vertically center */
        }
        .container img {
            margin-right: 10px; /* Adds space between the image and text */
        }
    </style>
</head>

<body>

	<div class="block_container"  style="background-color: #00b5e2; margin-left:3%; margin-right:50%;">    <p> </p>
    <p> </p>
    <br>



    <div id="block_container" >
    <p> </p>
    <p> </p>

        <h1> Deep Learning Recognition of Handwritten Digits</h1>
        <h2> CIIEC-BUAP</h2>
   <p style="font-size: 30px; margin-left: 80%;">October 18th, 2024 </p>
        <p style="font-size: 20px; margin-left: 80%;"><a href="https://github.com/lvillasen/
MNIST-Handwritten-Digit-Recognition" >Source Code</a> </p>

        <hr>

        <h2> Introduction</h2>

<p style="color:black;font-size:30px;">
This app illustrates the use of deep learning to train a model based on tensorflow.js to recognize handwritten digits cropped to images of 28x28 pixels with a convolutional neural network. The data used consists of the <a href="https://en.wikipedia.org/wiki/MNIST_database" >MNIST</a> handwitten dataset.
The code was adapted from <a href="https://storage.googleapis.com/tfjs-vis/mnist/dist/index.html" >this tutorial.</a>
This is an example of supervised machine learning.</p>

  <button class="new_styled"  id="open_visor" aria-pressed="false" style="background-color: lightgreen;">Open Visor</button>
  <button class="new_styled"  id="close_visor" aria-pressed="false" style="background-color: lightgreen;">Close Visor</button>
  <br>
  <br>

  <button class="new_styled"  id="toggleCode1" aria-pressed="false" >Load Data Code</button>
  <label>Images to Display: </label>
    <input id="n_images" style="width:5%;" value=100 type="text" >
  <button class="new_styled"  id="load" aria-pressed="false" style="background-color: lightgreen;">Load Data</button>

 <pre id="code1" style="background-color: lightblue; margin-left:5%; margin-right:5%; border:solid 5px #003b5c">
    
    import {MnistData} from './data.js';

    async function showExamples(data) {
      // Create a container in the visor
      const surface =
        tfvis.visor().surface({ name: 'Input Data Examples', tab: 'Input Data'});  

      // Get the examples
      const examples = data.nextTestBatch(20);
      const numExamples = examples.xs.shape[0];
      
      // Create a canvas element to render each example
      for (let i = 0; i < numExamples; i++) {
        const imageTensor = tf.tidy(() => {
          // Reshape the image to 28x28 px
          return examples.xs
            .slice([i, 0], [1, examples.xs.shape[1]])
            .reshape([28, 28, 1]);
        });
        
        const canvas = document.createElement('canvas');
        canvas.width = 28;
        canvas.height = 28;
        canvas.style = 'margin: 4px;';
        await tf.browser.toPixels(imageTensor, canvas);
        surface.drawArea.appendChild(canvas);

        imageTensor.dispose();
      }
    }

</pre>
<hr>

<button class="new_styled"  id="toggleCode2" aria-pressed="false" >Model Code</button>
  
  <button class="new_styled"  id="model" aria-pressed="false" style="background-color: lightgreen;">Model</button>

  <pre id="code2" style="background-color: lightblue; margin-left:5%; margin-right:5%; border:solid 5px #003b5c">
    
    function getModel() {
      const model = tf.sequential();
      
      const IMAGE_WIDTH = 28;
      const IMAGE_HEIGHT = 28;
      const IMAGE_CHANNELS = 1;  
      
      // In the first layer of our convolutional neural network we have 
      // to specify the input shape. Then we specify some parameters for 
      // the convolution operation that takes place in this layer.
      model.add(tf.layers.conv2d({
        inputShape: [IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS],
        kernelSize: 5,
        filters: 8,
        strides: 1,
        activation: 'relu',
        kernelInitializer: 'varianceScaling'
      }));

      // The MaxPooling layer acts as a sort of downsampling using max values
      // in a region instead of averaging.  
      model.add(tf.layers.maxPooling2d({poolSize: [2, 2], strides: [2, 2]}));
      
      // Repeat another conv2d + maxPooling stack. 
      // Note that we have more filters in the convolution.
      model.add(tf.layers.conv2d({
        kernelSize: 5,
        filters: 16,
        strides: 1,
        activation: 'relu',
        kernelInitializer: 'varianceScaling'
      }));
      model.add(tf.layers.maxPooling2d({poolSize: [2, 2], strides: [2, 2]}));
      
      // Now we flatten the output from the 2D filters into a 1D vector to prepare
      // it for input into our last layer. This is common practice when feeding
      // higher dimensional data to a final classification output layer.
      model.add(tf.layers.flatten());

      // Our last layer is a dense layer which has 10 output units, one for each
      // output class (i.e. 0, 1, 2, 3, 4, 5, 6, 7, 8, 9).
      const NUM_OUTPUT_CLASSES = 10;
      model.add(tf.layers.dense({
        units: NUM_OUTPUT_CLASSES,
        kernelInitializer: 'varianceScaling',
        activation: 'softmax'
      }));

      
      // Choose an optimizer, loss function and accuracy metric,
      // then compile and return the model
      const optimizer = tf.train.adam();
      model.compile({
        optimizer: optimizer,
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy'],
      });

      return model;
    }

</pre>

<hr>

<button class="new_styled"  id="toggleCode3" aria-pressed="false" >Training Code</button>
<br> 
<label>Batch Size: </label>
    <input id="n_batch" style="width:8%;" value=64 type="text" >
<label>Training Size: </label>
    <input id="n_train" style="width:8%;" value=512 type="text" >
<label>Testing Size: </label>
    <input id="n_test`" style="width:8%;" value=256 type="text" >
<label>Epochs: </label>
    <input id="n_epochs" style="width:6%;" value=30 type="text" >

  
  <button class="new_styled"  id="train" aria-pressed="false" style="background-color: lightgreen;">Train</button>
 <div class="progress-container">
    <progress id="progressBar" value="0" max="100" style="width: 100%;"></progress>
</div>
  <pre id="code3" style="background-color: lightblue; margin-left:5%; margin-right:5%; border:solid 5px #003b5c">
    
    async function train(model, data) {
      const metrics = ['loss', 'val_loss', 'acc', 'val_acc'];
      const container = {
        name: 'Model Training', tab: 'Model', styles: { height: '1000px' }
      };
      const fitCallbacks = tfvis.show.fitCallbacks(container, metrics);
      
      const BATCH_SIZE = 512;
      const TRAIN_DATA_SIZE = 12000;
      const TEST_DATA_SIZE = 2000;

      const [trainXs, trainYs] = tf.tidy(() => {
        const d = data.nextTrainBatch(TRAIN_DATA_SIZE);
        return [
          d.xs.reshape([TRAIN_DATA_SIZE, 28, 28, 1]),
          d.labels
        ];
      });

      const [testXs, testYs] = tf.tidy(() => {
        const d = data.nextTestBatch(TEST_DATA_SIZE);
        return [
          d.xs.reshape([TEST_DATA_SIZE, 28, 28, 1]),
          d.labels
        ];
      });

      return model.fit(trainXs, trainYs, {
        batchSize: BATCH_SIZE,
        validationData: [testXs, testYs],
        epochs: 10,
        shuffle: true,
        callbacks: fitCallbacks
      });
    }

</pre>
<hr>

<button class="new_styled"  id="toggleCode4" aria-pressed="false" >Evaluate Model Code</button>
<label>Evaluation Size: </label>
    <input id="n_test" style="width:6%;" value=2000 type="text" >
  
  <button class="new_styled"  id="evaluate" aria-pressed="false" style="background-color: lightgreen;">Evaluate</button>

  <pre id="code4" style="background-color: lightblue; margin-left:5%; margin-right:5%; border:solid 5px #003b5c">
    
    async function showAccuracy(model, data) {
      const [preds, labels] = doPrediction(model, data);
      const classAccuracy = await tfvis.metrics.perClassAccuracy(labels, preds);
      const container = {name: 'Accuracy', tab: 'Evaluation'};
      tfvis.show.perClassAccuracy(container, classAccuracy, classNames);

      labels.dispose();
    }

    async function showConfusion(model, data) {
      const [preds, labels] = doPrediction(model, data);
      const confusionMatrix = await tfvis.metrics.confusionMatrix(labels, preds);
      const container = {name: 'Confusion Matrix', tab: 'Evaluation'};
      tfvis.render.confusionMatrix(container, {values: confusionMatrix, 
      tickLabels: classNames});

      labels.dispose();
    }

</pre>

<hr>
  <button class="new_styled"  id="toggleCode5" aria-pressed="false" >Classify Code</button>
<pre id="code5" style="background-color: lightblue; margin-left:5%; margin-right:5%; border:solid 5px #003b5c">

   async function classify () {
      const tempCanvas = document.createElement('canvas');
      tempCanvas.width = 28;
      tempCanvas.height = 28;
      tempCanvas.style = 'margin: 4px;';
      const tempCtx = tempCanvas.getContext('2d');
      tempCtx.drawImage(canvas, 0, 0, 28, 28);
      tempCtx.fillStyle = "black";
      const outputCanvas = document.getElementById('outputCanvas');
      const outputCtx = outputCanvas.getContext('2d');
      outputCtx.fillStyle = "black";
      outputCtx.fillRect(0, 0, outputCanvas.width, outputCanvas.height);
      outputCtx.drawImage(tempCanvas, 0, 0);  
      const surface =
      tfvis.visor().surface({ name: 'Test Images', tab: 'Test'});
      const canvas1 = document.createElement('canvas');
      canvas1.width = 28;
      canvas1.height = 28;
      canvas1.style = 'margin: 4px;';
      surface.drawArea.appendChild(tempCanvas);
      clear();
      predictCanvasImage();
   }

   async function predictCanvasImage() {
      const outputCanvas = document.getElementById('outputCanvas');
      let tensor = tf.browser.fromPixels(outputCanvas, 1); 
      tensor = tensor.toFloat().div(tf.scalar(255));
      tensor = tensor.expandDims(0);
      try {
         const prediction = model.predict(tensor);
         const predictedDigit = prediction.argMax(1).dataSync()[0];
         document.getElementById('prediction').innerText = predictedDigit;
         bar_chart(prediction.dataSync());
      }
      catch(err) {
         bar_chart([.1,.1,.1,.1,.1,.1,.1,.1,.1,.1]);
      }
   }

</pre>

  <h3>Draw a Number Inside the Canvas</h3>

    <button class="new_styled" id="clearButton">Clear</button>    
  <button class="new_styled"  id="classify" aria-pressed="false" style="background-color: lightgreen;">Classify</button>
<div class="container">
    <canvas id="drawingCanvas"   style= " margin-left:0%;border:solid 5px white; width: 50%; display: block;
"></canvas>
        <canvas id="outputCanvas" width="28" height="28" style="margin-left:5%;border:4px white;"></canvas>
        <p style="font-size: 40px";>Predicted: <span id="prediction"></span></p>
    </div>
    <br>
<canvas id="barChart" style= " height:100px; margin-left:0%; width: 100%; "  ;></canvas>

	</div>
        <hr>
</body>
</html>
